{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,LabelBinarizer\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(r'D:\\datascience\\Copper_project\\Copper_Set.xlsx')\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_date1'] = pd.to_datetime(df['item_date'], format= '%Y%m%d', errors= 'coerce').dt.date\n",
    "df['quantity tons'] = pd.to_numeric(df['quantity tons'], errors='coerce')\n",
    "df['delivery date1'] = pd.to_datetime(df['delivery date'], format= '%Y%m%d', errors= 'coerce').dt.date\n",
    "df['material_ref'] = df['material_ref'].str.lstrip('0')\n",
    "df['material_ref'].fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['quantity tons'] < 0 , 'quantity tons'] = pd.NA\n",
    "df.loc[df['selling_price'] < 0 , 'selling_price'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country.fillna(df.country.mode()[0], inplace = True)\n",
    "df.application.fillna(df.application.mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, i):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    sns.boxplot(df[i])\n",
    "    plt.title(f'Box Plot for {i}')\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    sns.histplot(df[i], kde=True, bins=50)\n",
    "    plt.title(f'Distribution Plot for {i}')\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    sns.violinplot(df[i])\n",
    "    plt.title(f'Violin Plot for {i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "for i in numeric_columns:\n",
    "    plot(df1, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['quantity_log'] = np.log(df1['quantity tons'])\n",
    "df1['selling_price_log'] = np.log(df1['selling_price'])\n",
    "df1['thickness_log'] = np.log(df1['thickness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['item type', 'application', 'country',  'width', 'quantity_log', 'selling_price_log', 'thickness_log', 'status', 'product_ref']\n",
    "\n",
    "for i in col:\n",
    "    plot(df1, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df1.select_dtypes(include=['number'])\n",
    "correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_outliers(df, col):\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    df[col] = df[col].clip(lower_bound, upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()\n",
    "\n",
    "columns = ['width', 'quantity_log', 'selling_price_log', 'thickness_log']\n",
    "\n",
    "for i in columns:\n",
    "    iqr_outliers(df2, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in columns:\n",
    "    plot(df2, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df2[df2['status'].isin(['Won', 'Lost'])]\n",
    "dfc['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_class(x, y, algorithm):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    model = algorithm().fit(x_train, y_train)\n",
    "\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    y_pred_test = model.predict(x_test)\n",
    "\n",
    "    accuracy_train = metrics.accuracy_score(y_train, y_pred_train)\n",
    "    accuracy_test = metrics.accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    accuracy_metrics = {'algorithm'    : algorithm.__name__,\n",
    "                        'accuracy_train': accuracy_train,\n",
    "                        'accuracy_test' : accuracy_test}\n",
    "    \n",
    "    return accuracy_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = dfc[['quantity_log', 'thickness_log', 'customer', 'country','application', 'selling_price_log', 'width', 'product_ref', 'item type']]\n",
    "y1 = dfc['status']\n",
    "\n",
    "oh = OneHotEncoder(handle_unknown= 'ignore', categories=[dfc['item type'].unique()])\n",
    "oh.fit(x1[['item type']])\n",
    "x_enc = oh.fit_transform(x1[['item type']]).toarray()\n",
    "\n",
    "be = LabelBinarizer()\n",
    "be.fit(y1)\n",
    "y = be.fit_transform(y1).ravel()\n",
    "\n",
    "x = np.concatenate((x1[['quantity_log', 'thickness_log', 'customer', 'country','application', 'selling_price_log', 'width', 'product_ref']], x_enc), axis= 1)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x = scaler.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ml_class(x, y, DecisionTreeClassifier))\n",
    "print(ml_class(x, y, ExtraTreesClassifier))\n",
    "print(ml_class(x, y, RandomForestClassifier))\n",
    "print(ml_class(x, y, AdaBoostClassifier))\n",
    "print(ml_class(x, y, GradientBoostingClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth = 20, max_features = 'sqrt', min_samples_leaf = 1, min_samples_split = 2)\n",
    "\n",
    "rfc.fit(x_train, y_train)\n",
    "y_pred = rfc.predict(x_test)\n",
    "\n",
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\") #tn,fn,fp,tp\n",
    "print(result)\n",
    "result1 = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = dfc[['quantity_log', 'thickness_log', 'customer', 'country','application', 'selling_price_log', 'width', 'product_ref', 'item type']]\n",
    "y1 = dfc['status']\n",
    "\n",
    "oh = OneHotEncoder(handle_unknown= 'ignore', categories=[dfc['item type'].unique()])\n",
    "oh.fit(x1[['item type']])\n",
    "x_enc = oh.fit_transform(x1[['item type']]).toarray()\n",
    "\n",
    "be = LabelBinarizer()\n",
    "be.fit(y1)\n",
    "y = be.fit_transform(y1).ravel()\n",
    "\n",
    "x = np.concatenate((x1[['quantity_log', 'thickness_log', 'customer', 'country','application', 'selling_price_log', 'width', 'product_ref']], x_enc), axis= 1)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth = 20, max_features = 'sqrt', min_samples_leaf = 1, min_samples_split = 2)\n",
    "\n",
    "rfc.fit(x_train, y_train)\n",
    "y_pred = rfc.predict(x_test)\n",
    "\n",
    "result = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\") #tn,fn,fp,tp\n",
    "print(result)\n",
    "result1 = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP, TP, threshold = roc_curve(y_test, y_pred)\n",
    "auc_curve = auc(x=FP, y=TP)\n",
    "print(auc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(FP, TP, label=f\"ROC Curve (area={round(auc_curve, 2)}) \")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.10])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array([[5.45658, 1.15, 30156308, 32, 30, 6.6432, 1200, 628377, 'W']])\n",
    "test_data_numeric = np.array(test_data[:, [0, 1, 2, 3, 4, 5, 6, 7]], dtype=float)\n",
    "\n",
    "test_data_categorical = pd.DataFrame(test_data[:, [8]], columns=['item type'])\n",
    "\n",
    "test_data_oh = oh.transform(test_data_categorical).toarray()\n",
    "\n",
    "test_data_combined = np.concatenate((test_data_numeric, test_data_oh), axis=1)\n",
    "\n",
    "test_data_combined_scaled = scaler.transform(test_data_combined)\n",
    "\n",
    "pred = rfc.predict(test_data_combined_scaled)\n",
    "\n",
    "if pred == 1:\n",
    "    print(\"Won\")\n",
    "else:\n",
    "    print(\"Lost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\datascience\\Copper_project\\clasification_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(rfc, f)\n",
    "\n",
    "with open(r\"D:\\datascience\\Copper_project\\scaler.pkl\", 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "     \n",
    "with open(r\"D:\\datascience\\Copper_project\\encoder.pkl\", 'wb') as f:\n",
    "    pickle.dump(oh, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\datascience\\Copper_project\\clasification_model.pkl\", 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load the scaler\n",
    "with open(r\"D:\\datascience\\Copper_project\\scaler.pkl\", 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Load the OneHotEncoder\n",
    "with open(r\"D:\\datascience\\Copper_project\\encoder.pkl\", 'rb') as f:\n",
    "    oh = pickle.load(f)\n",
    "\n",
    "test_data = np.array([[5, 2.2, 30223043, 78, 10, 7.13, 1500, 1668701718, 'S']])\n",
    "test_data_numeric = np.array(test_data[:, [0, 1, 2, 3, 4, 5, 6, 7]], dtype=float)\n",
    "\n",
    "test_data_categorical = pd.DataFrame(test_data[:, [8]], columns=['item type'])\n",
    "\n",
    "test_data_oh = oh.transform(test_data_categorical).toarray()\n",
    "\n",
    "test_data_combined = np.concatenate((test_data_numeric, test_data_oh), axis=1)\n",
    "\n",
    "test_data_combined_scaled = scaler.transform(test_data_combined)\n",
    "\n",
    "pred = model.predict(test_data_combined_scaled)\n",
    "\n",
    "\n",
    "if pred == 1:\n",
    "    print(\"Won\")\n",
    "else:\n",
    "    print(\"Lost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.to_csv('D:\\\\datascience\\\\Copper_project\\\\copper_data_status.csv', index=False, header=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('D:\\\\datascience\\\\Copper_project\\\\copper_final_data.csv', index=False, header=True, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
